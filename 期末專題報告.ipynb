{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![封面](期末專題發表報名/封面.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目錄\n",
    "1. 選題動機\n",
    "2. 專案介紹\n",
    "3. 資料庫與資料介紹\n",
    "4. 實作規劃\n",
    "5. 文字探勘\n",
    "6. 語料預處理\n",
    "7. 模型簡介與實作\n",
    "8. 使用者介面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.選題動機\n",
    "    * 假貼文猖獗:輕則造成財物損失，重可造成人員傷亡\n",
    "    * NLP 分類問題應用廣泛，如: 電影評論\n",
    "    * 打擊假貼文:為眾多國家與社交媒體公司近年首要之務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.專案介紹\n",
    "## 題目啟發\n",
    "    * Kaggle Ongoing Competition\n",
    "    * 任務: 對災難性推特貼文，判斷真實性\n",
    "    * 評分: 放上Kaggle競賽平台，由平台公正資料測試預測準確度\n",
    "## 我們的專案\n",
    "1. 下載Kaggle資料集\n",
    "2. 訓練NLP、機器學習和深度學習模型\n",
    "3. 爬蟲抓取新的推特貼文，持續測試更新模型\n",
    "4. 透過`Heroku`雲平台進行模型上線部屬\n",
    "5. `LineBot聊天機器人`: \n",
    "    * 使用者介面\n",
    "    * 即時查詢留言，快速判斷真假\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.資料庫與資料介紹\n",
    "## 資料庫- Kaggle 資料集\n",
    "* Train Data\n",
    "* Test Data\n",
    "\n",
    "## 資料集介紹\n",
    "![封面](期末專題發表報名/投影片9.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.實作規劃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型介紹\n",
    "![封面](期末專題發表報名/投影片12.PNG)\n",
    "\n",
    "## 模型實做規劃\n",
    "![封面](期末專題發表報名/投影片13.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 文字探勘 \n",
    "![封面](期末專題發表報名/文字探勘.PNG)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.語料預處理 \n",
    "### 預處理: 正則表達式\n",
    "* 移除顏文字和一些怪符號\n",
    "* 移除 hashtag 的符號'#'\n",
    "* 移除人名標記\n",
    "* 移除網址\n",
    "* 全部小寫化\n",
    "* 移除無關用語: wa, ha, ve\n",
    "\n",
    "### 預處理: NLTK應用\n",
    "* 斷詞\n",
    "    * word_tokenize\n",
    "    * wordpunct_tokenize\n",
    "\n",
    "* 去停用字\n",
    "    * 停用字點\n",
    "    * 擴充停用詞表\n",
    "    \n",
    "### 文字雲\n",
    "![封面](期末專題發表報名/文字雲.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.模型簡介與實作\n",
    "## 程式碼連結(Google Drive):\n",
    "https://drive.google.com/drive/folders/10rcM9h9QnMJoL04jj8tv0MSAt0b-_1Xz?usp=sharing\n",
    "    * XGBoost\n",
    "    * BERT\n",
    "    * XLNet\n",
    "    \n",
    "## XGBoost 簡介\n",
    "\n",
    "* Tree Ensemble 模型\n",
    "* 改良 GBDT: 貪心法優化目標函式增幅\n",
    "* 建構於C++，運算速度快\n",
    "* 強擴展性\n",
    "    * 算法優化: 稀疏數據處理\n",
    "    * 系統優化: 並行式和分佈式計算、核外計算\n",
    "\n",
    "### 1. Tree Boosting\n",
    "#### (1)Ensemble tree\n",
    "* 三個臭皮匠勝過一個諸葛亮\n",
    "* Boosting: 分類器之間有關連\n",
    "\n",
    "#### (2)XGBoost 有別於傳統的 GBDT\n",
    "* 懲罰項的設計\n",
    "* 增量訓練\n",
    "\n",
    "#### (3)避免過度擬合的方法\n",
    "* Shrinkage：\n",
    "     削弱當前這棵樹的影響力，類似learning rate作用\n",
    "\n",
    "\n",
    "* Column ( feature ) subsampling：這個技巧在 RF 當中也有使用到，同時也有助於加快訓練速度\n",
    "\n",
    "### 2. Split finding algorithms (切分點查找算法)\n",
    "* Exact greedy algorithm (貪心算法獲取最優切分點):\n",
    "\t列舉所有可能\n",
    "\n",
    "* Approximate algorithm (近似算法):\n",
    "\t提出了候選分割點概念\n",
    "\n",
    "* Weighted quantile sketch (分佈式加權直方圖算法):\n",
    "\t近似算法和分佈式加權算法是為了解決數據無法一次載入內存\t或者在分佈式情況下（貪心算法）效率低的問題\n",
    "    \n",
    "### 3. System Design\n",
    "* Column block for parallel learning 記憶體優化\n",
    "  內存單元 block 中，採用 CSC 格式存放，以後均可使用\n",
    "\n",
    "* Cache-aware access: 快取優化，提升算法效率\n",
    "\n",
    "* Blocks for out-of-core computation:\n",
    "   塊壓縮和塊拆分，有助於平行運算時降低資料從硬碟讀取時間\n",
    "   \n",
    "### 4.  Comparison of Tree Boosting Systems\n",
    "![封面](期末專題發表報名/XG比較.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 實作\n",
    "1. 轉句向量　Bert-as-Service\n",
    "2. Import XGBoost: Dmatrix, 建模\n",
    "3. 調整超參數: GridSearch\n",
    "4. 模型表現\n",
    "5. PCA 降維\n",
    "![封面](期末專題發表報名/PCA降維.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 簡介\n",
    "\n",
    "* Bidirectional Encoder Representations from Transformer\n",
    "* 架構：Transformer中的Encoder\n",
    "* 傳統語言模型的變形\n",
    "* 一個能直接處理各式 NLP 任務的通用架構\n",
    "\n",
    "### 兩階段遷移學習！\n",
    "* 以LM Pretraining的方式，訓練出對自然語言有一定理解的模型\n",
    "* 用該模型做特徵擷取，或是fine-tune不同的下游監督式任務\n",
    "* 只要弄好第一步的模型，第二步就可用transfer learning來大大減低花費成本。\n",
    "\n",
    "### 預訓練任務\n",
    "1. 「克漏字填空」：學會處理每個詞在不同語境下該有的向量表示\n",
    "    * Masked Language Model, MLM\n",
    "    * 潮水「？」了，就知道誰沒穿褲子。\n",
    "2. 「下句預測」：學會處理兩個句子之間的關係\n",
    "    * Next Sentence Prediction, NSP\n",
    "    * 醒醒吧 + 你沒有妹妹 → OK？\n",
    "    * 用處：問答系統QA、自然語言推論NLI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 實作\n",
    "* 匯入套件與檢視\n",
    "* 資料處理(訓練資料)\n",
    "* 資料處理(測試資料)\n",
    "* 實作一個與BERT相容的Dataset\n",
    "* BERT的tokenizer\n",
    "\n",
    "![封面](期末專題發表報名/tokenizer.png)\n",
    "\n",
    "* 一次傳一小batch的dataloader\n",
    "* 拿出一個batch看看\n",
    "* 訂定測試準確率的函式\n",
    "* 參數數量\n",
    "    * 加上去的線性分類器如滄海一粟般渺小\n",
    "* 訓練\n",
    "* 測試、部分預測結果\n",
    "![封面](期末專題發表報名/BERT預測結果.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLNet 簡介\n",
    "\n",
    "### 自動編碼器(AE)\n",
    "* Auto Encoder, AE\n",
    "* BERT即屬之\n",
    "    * 優點：可以做到同時看上下文\n",
    "    * 缺點：\n",
    "        1. 克漏字(MLM)的預訓練階段，使用了[MASK] 遮罩，但是微調階段沒有。會造成資訊不對稱(Input Noise)。\n",
    "        2. BERT假設被預測的[MASK]獨立於未屏蔽的其他token，然而真正的自然語言中並非如此。\n",
    "        \n",
    "### 自回歸(AR)\n",
    "* 自回歸(Auto Regressive, AR)：利用前向的情景信息來預測下一個詞\n",
    "* 情景訊息通常有前後兩個方向\n",
    "    * 例如：「我 愛 吃 甜 蘋果」\n",
    "    * 如目標是「吃」，則：\n",
    "        * 前向情景為「我」和「愛」\n",
    "        * 後向就是「甜」和「蘋果」\n",
    "* GPT、ELMO皆屬之\n",
    "* 缺點：只能利用上文(前向)或者下文(後向)其中一個方向來判斷。然而一個詞通常是需要上下文一起判斷的。\n",
    "\n",
    "### XLNet!\n",
    "* 一種讓AR語言模型實現雙向學習的新方法\n",
    "    * 可避免MASK在BERT裡面帶來的缺點\n",
    "    * 又可避免AR語言模型只能單向學習的弊端\n",
    "    \n",
    "    \n",
    "* 作法、差異簡介\n",
    "    * 預訓練階段：還是用transformer的自注意(self-attention)機制\n",
    "    * 採取了一點改變：「置換語言建模」(Permutation Language Modeling, PLM)\n",
    "\n",
    "\n",
    "* 置換語言建模(PLM)![image.png]\n",
    "    * 例：tokens序列[x1，x2，x3，x4]\n",
    "        * 有24種「排列」(Permutation)\n",
    "    * 若要預測x3，則可分為4種模式\n",
    "        * x3在第1個位置\n",
    "        * x3在第2個位置\n",
    "        * x3在第3個位置\n",
    "        * x3在第4個位置\n",
    "    * 可考慮幾乎所有前後文情景模式！\n",
    "    * 實際上，如此要記錄的東西太多\n",
    "        * 作者不更動原始序列順序，而是用另一種\n",
    "        * 運用[MASK]的方式來實現AR + permutation。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLNet 實作\n",
    "* 匯入套件與資料\n",
    "* 資料清理(使用正則表達式)\n",
    "* XLNET的tokenizer\n",
    "* 建造模型\n",
    "* 分割資料集、產生tensor\n",
    "* ROC圖與AUC\n",
    "![封面](期末專題發表報名/ROC.png)\n",
    "* 定義回調函數(Callback fn.)\n",
    "* 訓練\n",
    "* 問題:\n",
    "    1. 梯度消失！\n",
    "    2. 資源耗盡！\n",
    "        * 記憶體被撐爆了！\n",
    "        * 解決方法：降低batch_size(20→5)，雖然慢了點，但至少可以動了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型比較\n",
    "![封面](期末專題發表報名/模型比較2.png)\n",
    "![封面](期末專題發表報名/模型比較.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.使用者介面: Line Bot\n",
    "## 為何選Line Bot\n",
    "* 易於使用，可以自動回復，在台灣2018年數據統計，達2100萬活躍用戶，高達九成使用率\n",
    "* 不需要安裝其他應用程式\n",
    "* 即時服務\n",
    "* 可以專注於後端處理\n",
    "* 可以處理群體回復\n",
    "* 成本低且安全\n",
    "\n",
    "![封面](期末專題發表報名/LineBot.png)\n",
    "\n",
    "## Line Bot原理\n",
    "1. 用戶發送訊息至LINE 官方帳號。\n",
    "2. LINE Platform 將一個 webhook 事件重送至bot server 的 webhook URL，也就是 deploy 於 Heruko 平台的server端。\n",
    "3. Bot server 將依據 webhook event，透過LINE Platform 回應用戶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![封面](期末專題發表報名/末頁.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
